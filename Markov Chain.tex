\documentclass[12pt, a4paper]{jsarticle}
    \usepackage{amsmath}
    \usepackage{amsthm}
    \usepackage[psamsfonts]{amssymb}
    \usepackage[dvipdfmx]{graphicx}
    \usepackage[dvipdfmx]{color}
    \usepackage{color}
    \usepackage{ascmac}
    \usepackage{amsfonts}
    \usepackage{mathrsfs}
    \usepackage{amssymb}
    \usepackage{graphicx}
    \usepackage{fancybox}
    \usepackage{enumerate}
    \usepackage{verbatim}
    \usepackage{subfigure}
    \usepackage{proof}

 

    %
    \theoremstyle{definition}
    %
    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    %ここにないパッケージを入れる人は，必ずここに記載すること．
    %
    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    %ここからはコード表です．
    %
   \newtheorem{axiom}{公理}[section]
    \newtheorem{defn}{定義}[section]
    \newtheorem{thm}{定理}[section]
    \newtheorem{prop}[thm]{命題}
    \newtheorem{lem}[thm]{補題}
    \newtheorem{cor}[thm]{系}
    \newtheorem{ex}{例}[section]
    \newtheorem{claim}{主張}[section]
    \newtheorem{property}{性質}[section]
    \newtheorem{attention}{注意}[section]
    \newtheorem{question}{問}[section]
    \newtheorem{prob}{問題}[section]
    \newtheorem{consideration}{考察}[section]
    \newtheorem{Alert}{警告}[section]
    \newtheorem{Rem}{注意}[section]
    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    %
    %定義や定理等に番号をつけたくない場合（例えば定理1.1等）は以下のコードを使ってください．
    %但し，例えば\Axiom*{}としてしまうと番号が付いてしまうので，必ず　\begin{Axiom*}　\end{Axiom*}の形で使ってください．
    \newtheorem*{axiom*}{公理}
    \newtheorem*{defn*}{定義}
    \newtheorem*{thm*}{定理}
    \newtheorem*{prop*}{命題}
    \newtheorem*{lem*}{補題}
    \newtheorem*{ex*}{例}
    \newtheorem*{cor*}{系}
    \newtheorem*{claim*}{主張}
    \newtheorem*{property*}{性質}
    \newtheorem*{attention*}{注意}
    \newtheorem*{question*}{問}
    \newtheorem*{prob*}{問題}
    \newtheorem*{consideration*}{考察}
    \newtheorem*{alert*}{警告}
    \newtheorem*{rem*}{注意}
    \renewcommand{\proofname}{\bfseries 証明}
    %
    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    %英語で定義や定理を書きたい場合こっちのコードを使うこと．
    \newtheorem{Axiom+}{Axiom}
    \newtheorem{Definition+}{Definition}
    \newtheorem{Theorem+}{Theorem}
    \newtheorem{Proposition+}{Proposition}
    \newtheorem{Lemma+}{Lemma}
    \newtheorem{Example+}{Example}
    \newtheorem{Corollary+}{Corollary}
    \newtheorem{Claim+}{Claim}
    \newtheorem{Property+}{Property}
    \newtheorem{Attention+}{Attention}
    \newtheorem{Question+}{Question}
    \newtheorem{Problem+}{Problem}
    \newtheorem{Consideration+}{Consideration}
    \newtheorem{Alert+}{Alert}
    %
    %
    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    %数
    \newcommand{\NN}{{\mathbb{N}}} %自然数全体，
    \newcommand{\ZZ}{{\mathbb{Z}}} %整数環
    \newcommand{\QQ}{{\mathbb{Q}}} %有理数体
    \newcommand{\RR}{{\mathbb{R}}} %実数体
    \newcommand{\CC}{{\mathbb{C}}} %複素数体
    \title{マルコフ連鎖まとめ}
    \author{@skbtkey}
    \date{}
\begin{document}
\maketitle
\begin{abstract}
この文書は卒研セミナーでのマルコフ連鎖のセミナーについて，毎回その要点をまとめるものである．気を付けなければいけないと思ったことは詳しく書く．また僕自身にとって簡単であるようなことは省略する．なお用いる教科書はPaul G. Hoel,Sideney C. Port, Charles J. Stone 著のIntroduction to Stochastic Processes．
\end{abstract}

\section{Markov Chain}\footnote{Markov Chainの訳は本によってさまざま．マルコフ系列だったりマルコフ過程だったりします．ここでは読んでいる教科書の用語を直訳することを意識してマルコフ鎖，マルコフ連鎖とします．}

\subsection{マルコフ性の定義}
$\mathcal{J}$は有限個の状態の集合とする．$\mathcal{J}$のことを{\bf 状態空間}とよぶ．離散時間$n = 0,1,2,\cdots$が与えられていて$X_n$はそれぞれの時刻$n$における状態を表すものする．($n \ge 0$)．この状態を数値に対応させることで$X_n$はある確率空間上の確率変数とみなす．
\begin{screen}
	\begin{defn}[マルコフ性]
		確率空間上(確率測度は$\mathbb{P}$)で定義された確率変数列$(X_n)_{n \in \NN}$がマルコフ性を満たすとは，次を満たすことである．
\begin{equation}
\mathbb{P}(X_{n+1} = x_{n+1} | X_0 = x_0 , \cdots , X_n = x_n) = \mathbb{P}(X_{n+1} = x_{n+1} | X_n = x_n) \label{markov property}
\end{equation}
	\end{defn}
\end{screen}

マルコフ性の式を言葉で説明してみよう．離散時間が与えられていてそれぞれの時刻で様々な状態を取るというモデルがある．計測開始時点から現在までの状態が分かっているとする．このとき，次の計測時点での状態が$x_{n+1}$であるような確率は，現在の状態のみに依存する．現在の状態さえわかっていれば過去の状態は一つ次の未来がどんな状態であるのかという確率には影響を与えない．

\begin{screen}
	\begin{defn}
		条件付き確率$\mathbb{P}(X_{n+1} = y | X_n = x)$のことを鎖の遷移確率(transition probabolities of the chain)という．
	\end{defn}
\end{screen}

この文書では変化しない遷移確率(stationary transition probability)を持つマルコフ鎖を考える．すなわち，$\mathbb{P}(X_{n+1} = y | X_n = x)$が$n$に依存しないようなマルコフ鎖のみを考える．$n$に依存しないとは，もっと具体的に言うと，
\[\mathbb{P}(X_{1} = y | X_0 = x) = \mathbb{P}(X_{2} = y | X_1 = x) = \cdots = \mathbb{P}(X_{n+1} = y | X_n = x)\]
が成り立つことを意味する．
\begin{screen}
	\begin{defn}(マルコフ鎖の定義)
		確率変数列$(X_n)_{n \in \NN}$がマルコフ鎖をなすとは，これらの確率変数たちがマルコフ性をもち，変化しない遷移確率をもつときにいう．
	\end{defn}
\end{screen}

\subsection{二つの状態をもつマルコフ鎖}
\begin{table}[h]
\caption{機械の状態と遷移の確率の様子}
\begin{center}
	\begin{tabular}{|c|c|c|} \hline
		$n$th day & 遷移確率 & $(n+1)$th day \\ \hline
		正常 & $\xrightarrow{q}$ & 故障 \\ \cline{2-3}
		\, & $\xrightarrow{1-q}$ & 正常 \\ \hline
		故障 & $\xrightarrow{p}$ & 正常 \\ \cline{2-3}
		\, & $\xrightarrow{1-p}$ & 故障 \\ \hline
	\end{tabular}
\end{center}

\end{table}
ある機械は1日の始まりに正常に動くか故障しているかチェックされる．表のように$n$日目の状態と$n+1$日目の状態の遷移の確率が定義されている．$0 \leq p,q \leq 1$である．機械が正常である時を$1$，故障しているときを$0$とする．$(X_n)_{n \in \NN}$を$n$日目の機械の状態を表すとする．このようにすると$(X_n)_{n \in \NN}$はマルコフ性を持つ確率変数であると考えられる（あくまでそんな気がする！）．
\[\mathbb{P}(X_{n+1} = 1|X_n = 0) = p\]
\[\mathbb{P}(X_{n+1} = 0|X_n = 1) = q\]
\[\mathbb{P}(X_0 = 0) =: \pi_0(0)\]
とおくと，$n$日目の状態が$x_n(=0 \, \text{or} \, 1)$である確率を計算することができる．
\begin{align*}
	\mathbb{P}(X_{n+1} = 0) &= \mathbb{P}(X_n = 0 \, \text{and}\, X_{n+1} = 0) + \mathbb{P}(X_n = 1 \, \text{and} \, X_{n+1} = 0) \\
	&= \mathbb{P}(X_n = 0)\mathbb{P}(X_{n+1} = 0 | X_{n} = 0) + \mathbb{P}(X_n = 1)\mathbb{P}(X_{n+1} = 0 | X_{n} = 1)\\
	&= \cdots \\
	&=(1-p-q)\mathbb{P}(X_n = 0) + q \\
\end{align*}
というふうに漸化式が得られるので，一般項を求める計算をすると，
\begin{equation}
\mathbb{P}(X_n = 0) = (1-p-q)^n\pi_0(0) + q \sum_{j=0}^{n-1}(1-p-q)^j
\end{equation}
総和を計算すると，
\begin{equation}
	\mathbb{P}(X_n = 0) = \frac{q}{p+q} + (1- p- q)^{n} \left( \pi_0(0) - \frac{q}{p+ q} \right) \label{3}
\end{equation}
が得られる．したがって，
\begin{equation}
	\mathbb{P}(X_n = 1) = \frac{p}{p+q} + (1- q- p)^{n} \left( \pi_0(1) - \frac{p}{q+ p} \right) \label{4}
\end{equation}
ここで，$p=q=1$でも$p=q=0$でもないとする．すなわち，$|1-p-q| < 1$であるから，$n \to \infty$とすると，
\[\lim_{n \to \infty} \mathbb{P}(X_n = 0) = \frac{q}{p+q}\]
\[\lim_{n \to \infty} \mathbb{P}(X_n = 1) = \frac{p}{p+q}\]

この機械の例では，先ほども述べたように，その日の機械の状態を指示している確率変数$(X_n)_{n \in \NN}$が本当にマルコフ性を持っているかどうかはわからない．実際，今までの計算でマルコフ性を用いてはいない．ここではこれらの確率変数たちがマルコフ性を持つと仮定して話を進める．すると，次のような計算が可能になる．$n = 2,x_0,x_1,x_2$は$1,0$のいずれかであるとき，
\begin{align*}
	& \mathbb{P}(X_0 = x_0 , X_1 = x_1, X_2 = x_2) \\
	= &\mathbb{P}(X_0 = x_0\, \text{and}\, X_1 = x_1)\mathbb{P}(X_2 = x_2 | X_0 = x_0\, \text{and}\, X_1 = x_1 ) \\
	=&\mathbb{P}(X_0 = x_0)\mathbb{P}(X_0 = x_0| X_1 = x_1)\mathbb{P}(X_2 = x_2 | X_1 = x_1)
\end{align*}
マルコフ性が無ければこの計算の2行目から3行目への変形はできない．それが意味するのは，$\mathbb{P}(X_0 = x_0 , X_1 = x_1, X_2 = x_2)$は$p,q,\pi_0$を用いて表すことができないということである．

\subsection{遷移関数と初期分布}
$(X_{n})_{n \in \NN}, n \ge 0 $を状態空間$\mathcal{J}$を持つマルコフ鎖とする．関数$P(x,y) (x,y \in \mathcal{J})$を次で定める．
\begin{equation}
	P(x,y) = \mathbb{P}(X_1 = y| X_0 = x) \,[x,y \in \mathcal{J}]
\end{equation}
これを鎖の遷移関数と呼ぶ．当然，
\begin{align}
	P(x,y) \ge 0 \label{trans fcn1} \\
	\sum_y P(x,y) = 1 \label{trans fcn2}
\end{align}
である．この文書ではマルコフ鎖は変化しない遷移確率をもつとしていたので，すなわち，
\begin{equation}
	\mathbb{P}(X_{n+1} = y| X_n = x) = P(x,y) \,[n \ge 1]
\end{equation}
が成立する．これと，マルコフ性より，
\begin{equation}
	\mathbb{P}(X_{n+1} = y | X_0 = x_0 , \cdots , X_n = x) = P(x,y)	
\end{equation}
が成り立つ．

また，関数$\pi_0$を次で定義する．
\begin{equation}
	\pi_0(x) = \mathbb{P}(X_0 = x ) \, [x \in \mathcal{J}]
\end{equation}
次が成り立つことは明らかである．
\begin{align}
	\pi_0(x) \ge 0 \label{pi_hihu}  \\
	\sum_x \pi_0(x) = 1 \label{pi_sum} 
\end{align}

これらの関数を用いるとマルコフ性を特徴づけすることができる．先ほども書いたように，
\begin{align*}
	& \mathbb{P}(X_0 = x_0 , X_1 = x_1, X_2 = x_2) \\
	=&\mathbb{P}(X_0 = x_0)\mathbb{P}(X_0 = x_0| X_1 = x_1)\mathbb{P}(X_2 = x_2 | X_1 = x_1)
\end{align*}
であるから，
\begin{align*}
	& \mathbb{P}(X_0 = x_0 , X_1 = x_1, X_2 = x_2) \\
	=& \pi_0(x_0) P(x_0,x_1)P(x_1,x_2)
\end{align*}
これを帰納的に計算することで，次を得る．
\begin{equation}
\mathbb{P}(X_0 = x_0 , \cdots , X_n = x_n) = \pi_0(x_0) P(x_0,x_1)P(x_1,x_2)\cdots P(x_{n-1},x_n) \label{markov feature} 
\end{equation}

ここで定義をまとめておく．
\begin{screen}
	\begin{defn}[遷移関数と初期分布]
		関数$P(x,y)\,[x,y \in \mathcal{J}]$が鎖の遷移関数であるとは，(\ref{trans fcn1})，(\ref{trans fcn2})を満たすことである．関数$\pi_0(x)\, [x \in \mathcal{J}]$が初期分布であるとは，(\ref{pi_hihu})，(\ref{pi_sum})を満たすことである．
	\end{defn}
\end{screen}

コロモゴロフの拡張定理より，遷移関数と初期分布が与えられると，ある確率空間とその空間の上で定義された確率変数列が式(\ref{markov feature})を満たすようなものが存在することを示すことができる．\footnote{後で書く}

少し計算をすれば，式(\ref{markov feature})が成立するならば，式(\ref{markov property})が成立することが分かる．よって，あるモデルにおいてマルコフ性が成り立つことを見るならば，式(\ref{markov feature})が成り立つかどうかを見ればよい．\footnote{要するに式(\ref{markov feature})が初期分布と遷移関数を用いたマルコフ性の特徴づけである}

\subsection{マルコフ連鎖の例}
私が読んだ本は7つほど例が載っていたが，すべてを書くのは辛いので一部を書きます．
\subsubsection{ランダムウォーク}
$\xi_1,\xi_2 \cdots$ は整数値の独立な確率変数で各$\xi_i$の確率密度関数は$f$で共通であるものとする．$X_0$を整数値の確率変数とし，各$\xi_i$と独立であるとする．$X_n = X_0 + \xi_1 + \cdots + \xi_n$とする．この時，確率変数列$(X_n)_{n \in \NN}$はマルコフ鎖をなし，俗にランダムウォークと呼ばれる．遷移関数はつぎであたえられる．
\[P(x,y) = f(y-x)\]
初期分布$\pi_0$は$X_0$の分布である．マルコフ性を満たすことを確認するために，式(\ref{markov feature})を満たすことを確認する．$X_n$の定義の式を睨み，$X_0$と各$\xi_i$が独立であることと，確率密度関数が$f$であること，遷移関数が上記の式で与えられていることを考えると次のような計算ができる．
\begin{align*}
&\mathbb{P}(X_0 = x_0,X_1 = x_1 ,\cdots ,X_n = x_n) \\
&= \mathbb{P}(X_0 = x_0,\xi_1 = x_1 - x_0, \cdots , \xi_n = x_n - x_{n-1}) \\
&= \mathbb{P}(X_0 = x_0)\mathbb{P}(\xi_1 = x_1 - x_0)\cdots \mathbb{P}(\xi_n = x_n - x_{n-1}) \\
&= \pi_0(x_0)f(x_1 - x_0)\cdots f(x_n - x_{n-1}) \\
&=\pi_0(x_0)P(x_1 , x_0)\cdots P(x_n , x_{n-1})
\end{align*}
（ランダムに整数が選ばれるというようなかなり人工的なマルコフ鎖のモデルだなと思うなど）

\subsubsection{Gambler's ruin chain}
あるギャンブラーが賭けをする．彼ははじめにいくらかお金を持っていて，毎ターンゲームをする．勝利すれば1ドル手に入れ，負けたら1ドル失う．引き分けはないものとする．ゲームに勝利する確率は$p$，負ける確率は$q:= 1-p$とする．所持金が尽きてしまった時，もうそれ以上ゲームができなくなってしまうのでそれ以降ずっと彼の所持金は0のままであるとする．$X_n$を$n$ターン目のゲーム終了時に彼が持っている所持金とする．この時，$(X_n)$はマルコフ鎖を成し，遷移関数は次で与えられる．
\begin{equation}
	P(x,y) = 
	\begin{cases}
		p, & (y = x + 1) \\
		q, & (y = x - 1) \\
		0, & (\text{otherwise})
	\end{cases}
\end{equation}
状態空間は$\NN$である．ある$n$で$X_n = 0$となってしまった場合，すべての$m \ge n$について$X_m = 0$のままであることに注意しよう．このような状態を普通absorbing stateという．
\begin{screen}
	\begin{defn}[absorbing state]
	状態$a \in \mathcal{J}$がabsorbing stateとは，$P(a,a) = 1$であること，すなわち$P(a,y) = 0 (y \neq a)$のときに言う．
	\end{defn}
\end{screen}

\subsection{遷移関数を用いたマルコフ鎖の計算}
遷移関数を用いてマルコフ鎖における様々な条件付き確率を計算しよう．
\begin{screen}
\begin{prop}
\begin{align}
&\mathbb{P}(X_{n+1} = x_{n+1}, \cdots,X_{n+m}=x_{n+m} | X_0 = x_0 ,\cdots, X_n = x_n) \notag \\
 = &P(x_n,x_{n+1})\cdots P(x_{n+m-1} ,x_{n+m}) \label{15} 
\end{align}
\end{prop}
\end{screen}
\begin{proof}
左辺を条件付き確率の定義に従って変形し，式(\ref{markov feature})を用いて計算すると右辺を得る．
\end{proof}
式(\ref{15})は次のように書き直しておくと今後便利である．
\begin{align}
&\mathbb{P}(X_{n+1} = y_{1}, \cdots,X_{n+m}=y_{m} | X_0 = x_0 ,\cdots,X_{n-1}= x_{n-1}, X_n = x) \notag \\
 = & P(x,y_{1})\cdots P(y_{m-1} ,y_{m}) \label{16}
\end{align}
式(\ref{16})と4(a) \footnote{後で主張を書いておくこと} より，$A_0,A_1,\cdots,A_{n-1} \subset \mathcal{J}$に対して，
\begin{align}
&\mathbb{P}(X_{n+1} = y_{1}, \cdots,X_{n+m}=y_{m} | X_0 \in A_0 ,\cdots,X_{n-1} \in A_{n-1}, X_n = x) \notag \\
 = & P(x,y_{1})\cdots P(y_{m-1} ,y_{m}) \label{17}
\end{align}
これと，4(b)\footnote{これもあとで主張を書いておく}より，$B_1,\cdots,B_{m} \subset \mathcal{J}$とすると，
\begin{align}
&\mathbb{P}(X_{n+1} \in B_1, \cdots,X_{n+m} \in B_m | X_0 \in A_0 ,\cdots,X_{n-1} \in A_{n-1}, X_n = x) \notag \\
 = &\sum_{y_1 \in B_1} \cdots \sum_{y_m \in B_m} P(x,y_{1})\cdots P(y_{m-1} ,y_{m}) \label{18}
\end{align}

\begin{screen}
	\begin{defn}
		$x$が$m$ステップで$y$にうつりゆく確率を返す$m-step$の遷移関数$P^m (x,y)$は次で定義される．
		\begin{align}
			P^m(x,y) = \sum_{y_1} \cdots \sum_{y_{m-1}} P(x,y_1) \cdots P(y_{m-1},y_{m}) \label{19}
		\end{align}
		ただし，$m=1$のとき，$P^1(x,y) = P(x,y)$とし，$m=0$の時は，
		\[P^0(x,y) = \begin{cases}
			1 & (x=y) \\
			0 & (\text{otherwise})
\end{cases}\]
	\end{defn}
\end{screen}
式(\ref{18})で$B_1 = \cdots = B_{m-1} = \mathcal{J}, B_m = \{y\}$とすると，右辺が式(\ref{19})の右辺と同じになるから，
\begin{equation}
	\mathbb{P}(X_{n+m} = y | X_0 \in A_0 ,\cdots,X_{n-1} \in A_{n-1}, X_n = x) = P^m(x,y) \label{20}
\end{equation}
この式において$A_0 = A_{n-1} = \mathcal{J}$とおけば，
\begin{equation}
	\mathbb{P}(X_{n+m} = y | X_n = x) = P^m(x,y) \label{21}
\end{equation}
が得られるし，$A_0 = \{z\} ,A_1 = \cdots = A_{n-1} = \mathcal{J}$とすれば，
\begin{equation}
	\mathbb{P}(X_{n+m} = y | X_0 = z , X_n = x) = P^m(x,y)  \label{22}
\end{equation}
が得られる．4(c)\footnote{主張を書いておく．式変形の一行目から二行目で用いているぽい}より，
\begin{align*}
	P^{n+m}(x,y) &= \mathbb{P}(X_{n+m} = y | X_0 = x) \\
	&= \sum_{z \in \mathcal{J}} \mathbb{P}(X_n = z | X_0 = x) \mathbb{P}(X_{n+m} = y | X_0 = x, X_n = z) \\
	&= \sum_{z \in \mathcal{J}} P^n(x,z)\mathbb{P}(X_{n+m} = y | X_0 = x, X_n = z)
\end{align*}
が分かるから式(\ref{22})を用いると，
\begin{equation}
	P^{n+m} (x,y) =  \sum_{z \in \mathcal{J}} P^n(x,z) P^m(z,y) \label{23}
\end{equation}
とあらわせる．状態空間が有限集合のMarkov Chainを考えているなら，式(\ref{23})は$P^n$を行列$P$の$n$乗として見てもよいことになる．詳しくは後に語られる．

初期分布も計算に組み込もう．$\pi_0$をMarkov Chain の初期分布関数とすると，
\begin{align*}
	P(X_n = y) &= \sum_{x \in \mathcal{J}}\mathbb{P} (X_0 = x, X_n = y) \\
	&= \sum_{x \in \mathcal{J}} \mathbb{P}(X_0 = x) \mathbb{P}(X_n = y | X_0 = x)
\end{align*}
だから，
\begin{equation}
	P(X_n = y) = \sum_{x \in \mathcal{J}} \pi_0(x) P^n(x,y) \label{24}
\end{equation}
を得る．遷移関数を使うことで別のアプローチで$\mathbb{P}(X_{n+1} = y)$を計算することができる．
\begin{align*}
\mathbb{P}(X_{n+1} = y) &= \sum_{x \in \mathcal{J}} \mathbb{P}(X_n = x, X_{n+1} = y) \\
&= \sum_{x \in \mathcal{J}} \mathbb{P}(X_n = x)\mathbb{P}(X_{n+1} = y | X_n = x) \\
\end{align*}
より，
\begin{equation}
\mathbb{P}(X_{n+1} = y) = \sum_{x \in \mathcal{J}} \mathbb{P}(X_n = x) P(x,y) \label{25}
\end{equation}
という漸化式が得られるので初期分布$\pi_0(x)$から始めて帰納的に計算することができる．

ここで新しい記号を導入する．
\begin{screen}
	\begin{defn}
	$P_x (・)$は状態$x$からスタートするMarkov Chainにおける様々な事象の確率を表すことにする
	\end{defn}
\end{screen}
例えば，$P_x(X_1 \neq a,X_2 \neq a,X_3 = a)$とは，$x$からスタートするMarkov Chainが時刻3で初めて状態$a$に到達するような確率を表している．$P_x()$を用いて式(\ref{18})を次のように書くことができる．
\begin{align}
&\mathbb{P}(X_{n+1} \in B_1, \cdots,X_{n+m} \in B_m | X_0 \in A_0 ,\cdots,X_{n-1} \in A_{n-1}, X_n = x) \notag \\
 = &P_x(X_1 \in B_1,\cdots, X_m \in B_m) \label{26}
\end{align}
この式は後の議論を進めるなかでの計算でよく使割れる．

\subsubsection{Hitting Times}
\begin{screen}
\begin{defn}[Hitting Times]
$A$を$\mathcal{J}$の部分集合とする．$T_A$を$A$のHitting Timeといい，次で定義する．
\[T_A = min(n > 0 | X_n \in A)\]
ただし，$X_n \in T_A$となる$n$がないときは$T_A = \infty$とする．
$A$が一点集合$\{a\}$であったとき，$T_{\{a\}}$を単に$T_a$と書くことにする．
\end{defn}
\end{screen}
$T_A$は考えているMarkov Chainが初めて$A$と「ぶつかる」時刻とみてよい．次の等式はHitting Timeを扱うときによく使う大切な式である．

\begin{screen}
	\begin{lem} \label{lem1-2}
	\[P^n (x,y) = \sum_{m = 1}^{n} P_x(T_y = m)P^{n-m}(y,y)\]
	\end{lem}
\end{screen}
\begin{proof}
$\{T_y = m, X_n =y\} \quad (1 \leq m \leq n)$という事象は$m$ごとに互いに素である．\footnote{$m$が変化するとは$T_y$の値が変わってしまうことだから，$\{y\}$のHitting Timeが異なるということ．よって，必ず自傷同士の共通部分は空集合になる}
また，
\[ \{X_n = y\} = \bigcup_{m=1}^{n} \{ T_y = m , X_n = y \} \]
である．(左辺を$T_y$の値について分解した．)
よって，
\begin{align*}
P^n(x,y) &= P_x(X_n = y) \\
&= \sum_{m = 1}^{n} P_x(T_y =m, X_n = y) 　\\
&= \sum_{m= 1}^{n} P_x(T_y = m) \mathbb{P}(X_n = y | X_0 = x, T_y = m) \\
&= \sum_{m= 1}^{n} P_x(T_y = m) \mathbb{P}(X_n = y | X_0 = x, X_1 \neq y, \cdots ,X_{m-1} \neq y, X_m =y) \\
&= \sum_{m= 1}^{n} P_x(T_y = m)P^{n-m}(y,y) 
\end{align*}
一行目から二行目は各事象はdisjointより．四行目から五行目は式(\ref{22})を適用した．
\end{proof}

\begin{ex}
$a$がabsorbing stateなら$P^n(x,a) = P_x(T_a \leq n)$である．ただし，$P_x(T_a \leq n) = \displaystyle \sum_{m = 1}^n P_x(T_a = m)$である．実際，$P^{n-m}(a,a) = 1$であるから補題\ref{lem1-2}を適用すると，
\begin{align*}
P_x(T_a \leq n) &= \sum_{m = 1}^n P_x(T_a = m)P^{n-m}(a,a) \\
&= \sum_{m = 1}^n P_x(T_a = m) \\
&= P_x(T_a \leq n)
\end{align*}
となる．
\end{ex}

$T_y = 1,2$のような時に観察すると，次が成り立つことが予想できる．
\begin{equation}
	P_x(T_y = n+1) =  \sum_{z \neq y}P(x,z)P_z(T_y = n) \quad [n \geq 1]　
\end{equation}
直観的には，まず最初の1ステップで$y$ではない状態$z$に行き，そこから$z$をスタートとするMarkov Chainだと思い，その$\{y\}$のHitting Timeが$n$，つまり$P_z(T_y = n)$を考えればよい．式(\ref{26})からも求めることができる．$x$から始まるMarkov Chainを考える．$\mathbb{P}(X_0 = x) = 1$であることに注意しておくと次の計算ができる．
\begin{align*}
P_x(T_y = n+1) =& \mathbb{P}(X_0 = x ,X_1 \neq y, \cdots, X_n \neq y, X_{n+1} = y) \\
=& \mathbb{P}(X_2 \neq y,\cdots,X_n\neq y, X_{n+1} = y | X_0 = x, X_1 \neq y)\\
& \mathbb{P}(X_0 = x,X_1 \neq y) \\
=& \mathbb{P}(X_2 \neq y,\cdots,X_n\neq y, X_{n+1} = y | X_0 = x, X_1 \neq y)\\
& \mathbb{P}(X_1 \neq y | X_0 = x)\mathbb{P}(X_0 = x) \\
=& \mathbb{P}(X_2 \notin \{y\},\cdots,X_n \notin \{y\}, X_{n+1} \in \{y\} | X_0 \in \{x\}, X_1 \notin \{y\})  \\
& \mathbb{P}(X_1 \neq y | X_0 = x) \\
=& \sum_{z \neq y}P_z(X_1\notin \{y\} , \cdots , X_{n-1} \notin \{y\}, X_n \notin \{y\}) P(x,z) \\
=& \sum_{z \neq y}P_z(X_1\neq y , \cdots , X_{n-1} \neq y, X_n = y) P(x,z) \\
=& \sum_{z \neq y}P_z(T_y = n) P(x,z)
\end{align*}
見やすく書いておくと，
\begin{equation}
P_x(T_y = n+1) = \sum_{z \neq y}P_z(T_y = n) P(x,z)
\end{equation}
$n+1$ステップ目で初めて$y$に到達する確率は，まず，$1$ステップ目で$y$ではない$z$という状態に動いて，その後$n$ステップで$y$に到達する確率を全て足し合わせればよい．

\subsubsection{遷移行列}
状態空間を$\mathcal{J} = \{0,1, \cdots , d\}$とする．すると遷移関数$P : \mathcal{J} \times \mathcal{J} \rightarrow [0,1]$を行列として捉えることができる．その行列は$(d+1) \times (d+1)$行列で第$(i,j)$成分は$P(i,j)$である．
\[
\begin{pmatrix}
P(0,0) & \cdots & P(0,d) \\
\vdots & \ddots & \vdots \\
P(d,0) & \cdots & P(d,d)
\end{pmatrix}
\]
このように定義すると，上記の行列の積と$n-$step遷移関数を同一視できる．式(\ref{23})で$n=m=1$とすれば
\begin{equation}
	P^{2}(x,y) = \sum_z P(x,z)P(z,y)
\end{equation}
となり，通常の行列の積の$(x,y)$成分の定義と同じなので$2-$ステップ遷移関数と遷移行列$P$の2乗は同一視してよい．次に式(\ref{23})で$m=1$とすれば
\begin{equation}
	P^{n+1}(x,y) = \sum_n P^n(x,z)P(z,y)
\end{equation}
となり，帰納的に，$n-$ステップ遷移関数$P^n$は遷移行列$P$の$n$乗と同一視してよい．

初期分布$\pi_0$も$d+1$個の成分を持つ行ベクトルと考えることができる．
\[
\pi_0 = (\pi_0(0), \cdots , \pi_0(d))
\]
$\pi_n$を$d+1$個の成分を持つ行ベクトルで，
\[
\pi_n = (\mathbb{P}(X_n =0), \cdots , \mathbb{P}(X_n = d))
\]
とすれば，式(\ref{24})(\ref{25})より
\begin{align*}
\pi_n = \pi_0 P^n \\
\pi_{n+1} = \pi_n P
\end{align*}
が分かる．

\begin{ex}
状態が二つしかないMarkov Chainを考える．遷移行列は
\[P=
\begin{pmatrix}
1-p & p \\
q & 1-q
\end{pmatrix}
\]
で与えられているものとする(ただし$p+q > 0$とする)．
\end{ex}
式(\ref{3})(\ref{4})より，それぞれの場合で$\pi_0(0) = 1 ,\pi_0(1) = 1$とすれば，
\begin{align*}
P^n(0,0) = \frac{q}{p+q} + (1-p-q)^n \frac{p}{p+q} \\
P^n(0,1) = \frac{p}{p+q} - (1-p-q)^n \frac{p}{p+q} \\
\intertext{同様に，}
P^n(1,0) = \frac{q}{p+q} + (1-p-q)^n \frac{q}{p+q} \\
P^n(1,1) = \frac{p}{p+q} - (1-p-q)^n \frac{q}{p+q}
\end{align*}
これで各成分が出そろったので，遷移行列の$n$乗は
\[
P^n = \frac{1}{p+q} \begin{pmatrix}
q & p \\
q & p
\end{pmatrix}
+ \frac{(1-p-q)^n}{p+q} \begin{pmatrix}
p & -p \\
-q & q
\end{pmatrix}
\]
と計算できる．

\subsection{Transient state と Recurrent state}



























\end{document}